{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(320, 50)\n",
    "        self.fc2 = torch.nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 28 X 28 --> 24 X 24(by convolution) --> 12 X 12 (by max_pool2d)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # 12 X 12 --> 8 X 8(by convolution) --> 4 X 4 (by max_pool2d)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # 4 X 4 X 20 == 320\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "        \n",
    "def fit(epoch, model, data_loader, phase='training', volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        \n",
    "        running_loss += torch.nn.functional.nll_loss(output, target, reduction='none').data[0]\n",
    "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct / len(data_loader.dataset)\n",
    "        \n",
    "    print(f'{phase} loss is {loss:5.2f} and {phase} accuracy is {running_correct} / {len(data_loader.dataset)} {accuracy:10.4f}')\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.02 and training accuracy is 46476 / 60000    77.4600\n",
      "validation loss is  0.00 and validation accuracy is 9575 / 10000    95.7500\n",
      "training loss is  0.01 and training accuracy is 54351 / 60000    90.5850\n",
      "validation loss is  0.00 and validation accuracy is 9692 / 10000    96.9200\n",
      "training loss is  0.01 and training accuracy is 55509 / 60000    92.5150\n",
      "validation loss is  0.00 and validation accuracy is 9772 / 10000    97.7200\n",
      "training loss is  0.01 and training accuracy is 56096 / 60000    93.4933\n",
      "validation loss is  0.00 and validation accuracy is 9794 / 10000    97.9400\n",
      "training loss is  0.01 and training accuracy is 56519 / 60000    94.1983\n",
      "validation loss is  0.00 and validation accuracy is 9818 / 10000    98.1800\n",
      "training loss is  0.01 and training accuracy is 56711 / 60000    94.5183\n",
      "validation loss is  0.00 and validation accuracy is 9839 / 10000    98.3900\n",
      "training loss is  0.01 and training accuracy is 56924 / 60000    94.8733\n",
      "validation loss is  0.00 and validation accuracy is 9843 / 10000    98.4300\n",
      "training loss is  0.01 and training accuracy is 57098 / 60000    95.1633\n",
      "validation loss is  0.00 and validation accuracy is 9857 / 10000    98.5700\n",
      "training loss is  0.00 and training accuracy is 57310 / 60000    95.5167\n",
      "validation loss is  0.00 and validation accuracy is 9858 / 10000    98.5800\n",
      "training loss is  0.01 and training accuracy is 57305 / 60000    95.5083\n",
      "validation loss is  0.00 and validation accuracy is 9860 / 10000    98.6000\n",
      "training loss is  0.00 and training accuracy is 57464 / 60000    95.7733\n",
      "validation loss is  0.00 and validation accuracy is 9861 / 10000    98.6100\n",
      "training loss is  0.00 and training accuracy is 57534 / 60000    95.8900\n",
      "validation loss is  0.00 and validation accuracy is 9876 / 10000    98.7600\n",
      "training loss is  0.00 and training accuracy is 57632 / 60000    96.0533\n",
      "validation loss is  0.00 and validation accuracy is 9873 / 10000    98.7300\n",
      "training loss is  0.00 and training accuracy is 57596 / 60000    95.9933\n",
      "validation loss is  0.00 and validation accuracy is 9886 / 10000    98.8600\n",
      "training loss is  0.00 and training accuracy is 57697 / 60000    96.1617\n",
      "validation loss is  0.00 and validation accuracy is 9880 / 10000    98.8000\n",
      "training loss is  0.00 and training accuracy is 57712 / 60000    96.1867\n",
      "validation loss is  0.00 and validation accuracy is 9887 / 10000    98.8700\n",
      "training loss is  0.00 and training accuracy is 57738 / 60000    96.2300\n",
      "validation loss is  0.00 and validation accuracy is 9892 / 10000    98.9200\n",
      "training loss is  0.00 and training accuracy is 57817 / 60000    96.3617\n",
      "validation loss is  0.00 and validation accuracy is 9892 / 10000    98.9200\n",
      "training loss is  0.00 and training accuracy is 57799 / 60000    96.3317\n",
      "validation loss is  0.00 and validation accuracy is 9891 / 10000    98.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20cb3748e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54617 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 44160 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 51613 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54617 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 44160 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "E:\\Users\\dbsrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 51613 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('data/', train=True, transform=transformation, download=True)\n",
    "test_dataset = datasets.MNIST('data/', train=False, transform=transformation, download=True)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = Network()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "train_losses, train_accuracy = [], []\n",
    "val_losses, val_accuracy = [], []\n",
    "for epoch in range(1, 20):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch, model, train_loader, phase='training')\n",
    "    val_epoch_loss, val_epoch_accuracy = fit(epoch, model, test_loader, phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "    \n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, 'bo', label = '학습 정확도')\n",
    "plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, 'r', label = '검증 정확도')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-2-0b18e8b7a1ca>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-0b18e8b7a1ca>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
